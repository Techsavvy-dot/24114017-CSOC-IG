{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.11","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":12045285,"sourceType":"datasetVersion","datasetId":7579967},{"sourceId":12045302,"sourceType":"datasetVersion","datasetId":7579982}],"dockerImageVersionId":31040,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import numpy as np \nimport pandas as pd\n!pip install gensim","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2025-06-07T17:02:45.784978Z","iopub.execute_input":"2025-06-07T17:02:45.785392Z","iopub.status.idle":"2025-06-07T17:02:58.977953Z","shell.execute_reply.started":"2025-06-07T17:02:45.785358Z","shell.execute_reply":"2025-06-07T17:02:58.976781Z"}},"outputs":[{"name":"stdout","text":"Requirement already satisfied: gensim in /usr/local/lib/python3.11/dist-packages (4.3.3)\nRequirement already satisfied: numpy<2.0,>=1.18.5 in /usr/local/lib/python3.11/dist-packages (from gensim) (1.26.4)\nCollecting scipy<1.14.0,>=1.7.0 (from gensim)\n  Downloading scipy-1.13.1-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (60 kB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m60.6/60.6 kB\u001b[0m \u001b[31m2.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hRequirement already satisfied: smart-open>=1.8.1 in /usr/local/lib/python3.11/dist-packages (from gensim) (7.1.0)\nRequirement already satisfied: mkl_fft in /usr/local/lib/python3.11/dist-packages (from numpy<2.0,>=1.18.5->gensim) (1.3.8)\nRequirement already satisfied: mkl_random in /usr/local/lib/python3.11/dist-packages (from numpy<2.0,>=1.18.5->gensim) (1.2.4)\nRequirement already satisfied: mkl_umath in /usr/local/lib/python3.11/dist-packages (from numpy<2.0,>=1.18.5->gensim) (0.1.1)\nRequirement already satisfied: mkl in /usr/local/lib/python3.11/dist-packages (from numpy<2.0,>=1.18.5->gensim) (2025.1.0)\nRequirement already satisfied: tbb4py in /usr/local/lib/python3.11/dist-packages (from numpy<2.0,>=1.18.5->gensim) (2022.1.0)\nRequirement already satisfied: mkl-service in /usr/local/lib/python3.11/dist-packages (from numpy<2.0,>=1.18.5->gensim) (2.4.1)\nRequirement already satisfied: wrapt in /usr/local/lib/python3.11/dist-packages (from smart-open>=1.8.1->gensim) (1.17.2)\nRequirement already satisfied: intel-openmp<2026,>=2024 in /usr/local/lib/python3.11/dist-packages (from mkl->numpy<2.0,>=1.18.5->gensim) (2024.2.0)\nRequirement already satisfied: tbb==2022.* in /usr/local/lib/python3.11/dist-packages (from mkl->numpy<2.0,>=1.18.5->gensim) (2022.1.0)\nRequirement already satisfied: tcmlib==1.* in /usr/local/lib/python3.11/dist-packages (from tbb==2022.*->mkl->numpy<2.0,>=1.18.5->gensim) (1.3.0)\nRequirement already satisfied: intel-cmplr-lib-rt in /usr/local/lib/python3.11/dist-packages (from mkl_umath->numpy<2.0,>=1.18.5->gensim) (2024.2.0)\nRequirement already satisfied: intel-cmplr-lib-ur==2024.2.0 in /usr/local/lib/python3.11/dist-packages (from intel-openmp<2026,>=2024->mkl->numpy<2.0,>=1.18.5->gensim) (2024.2.0)\nDownloading scipy-1.13.1-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (38.6 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m38.6/38.6 MB\u001b[0m \u001b[31m37.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hInstalling collected packages: scipy\n  Attempting uninstall: scipy\n    Found existing installation: scipy 1.15.2\n    Uninstalling scipy-1.15.2:\n      Successfully uninstalled scipy-1.15.2\n\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\ntsfresh 0.21.0 requires scipy>=1.14.0; python_version >= \"3.10\", but you have scipy 1.13.1 which is incompatible.\ncesium 0.12.4 requires numpy<3.0,>=2.0, but you have numpy 1.26.4 which is incompatible.\ndopamine-rl 4.1.2 requires gymnasium>=1.0.0, but you have gymnasium 0.29.0 which is incompatible.\nimbalanced-learn 0.13.0 requires scikit-learn<2,>=1.3.2, but you have scikit-learn 1.2.2 which is incompatible.\nplotnine 0.14.5 requires matplotlib>=3.8.0, but you have matplotlib 3.7.2 which is incompatible.\nmlxtend 0.23.4 requires scikit-learn>=1.3.1, but you have scikit-learn 1.2.2 which is incompatible.\u001b[0m\u001b[31m\n\u001b[0mSuccessfully installed scipy-1.13.1\n","output_type":"stream"}],"execution_count":1},{"cell_type":"code","source":"train_df = pd.read_csv(r'/kaggle/input/train-csv/train.csv')","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-07T17:02:58.980084Z","iopub.execute_input":"2025-06-07T17:02:58.980897Z","iopub.status.idle":"2025-06-07T17:03:40.813704Z","shell.execute_reply.started":"2025-06-07T17:02:58.980858Z","shell.execute_reply":"2025-06-07T17:03:40.812887Z"}},"outputs":[],"execution_count":2},{"cell_type":"code","source":"test_df = pd.read_csv('/kaggle/input/train-csv/train.csv')","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-07T17:03:40.814547Z","iopub.execute_input":"2025-06-07T17:03:40.814837Z","iopub.status.idle":"2025-06-07T17:04:02.990320Z","shell.execute_reply.started":"2025-06-07T17:03:40.814808Z","shell.execute_reply":"2025-06-07T17:04:02.989156Z"}},"outputs":[],"execution_count":3},{"cell_type":"code","source":"train_df = train_df.dropna()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-07T17:04:02.993354Z","iopub.execute_input":"2025-06-07T17:04:02.993680Z","iopub.status.idle":"2025-06-07T17:04:03.999390Z","shell.execute_reply.started":"2025-06-07T17:04:02.993650Z","shell.execute_reply":"2025-06-07T17:04:03.998538Z"}},"outputs":[],"execution_count":4},{"cell_type":"code","source":"train_df.iloc[:,0].value_counts()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-07T17:04:04.000319Z","iopub.execute_input":"2025-06-07T17:04:04.000616Z","iopub.status.idle":"2025-06-07T17:04:04.037397Z","shell.execute_reply.started":"2025-06-07T17:04:04.000596Z","shell.execute_reply":"2025-06-07T17:04:04.036605Z"}},"outputs":[{"execution_count":5,"output_type":"execute_result","data":{"text/plain":"2\n2    1799912\n1    1799880\nName: count, dtype: int64"},"metadata":{}}],"execution_count":5},{"cell_type":"markdown","source":"# RNN ","metadata":{}},{"cell_type":"code","source":"sentences = [review.split() for review in train_df.iloc[:,2]]","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-07T17:04:04.038443Z","iopub.execute_input":"2025-06-07T17:04:04.038750Z","iopub.status.idle":"2025-06-07T17:05:15.060215Z","shell.execute_reply.started":"2025-06-07T17:04:04.038728Z","shell.execute_reply":"2025-06-07T17:05:15.059143Z"}},"outputs":[],"execution_count":6},{"cell_type":"code","source":"from gensim.models import KeyedVectors,Word2Vec","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-07T17:05:15.061451Z","iopub.execute_input":"2025-06-07T17:05:15.061733Z","iopub.status.idle":"2025-06-07T17:05:58.252896Z","shell.execute_reply.started":"2025-06-07T17:05:15.061712Z","shell.execute_reply":"2025-06-07T17:05:58.252169Z"}},"outputs":[],"execution_count":7},{"cell_type":"code","source":"model = Word2Vec(sentences, vector_size=16, window=3, min_count=100000, workers=1000) \nmodel.wv.save_word2vec_format(\"got_word2vec.txt\", binary=False)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-07T17:05:58.253845Z","iopub.execute_input":"2025-06-07T17:05:58.254877Z","iopub.status.idle":"2025-06-07T17:13:44.914284Z","shell.execute_reply.started":"2025-06-07T17:05:58.254841Z","shell.execute_reply":"2025-06-07T17:13:44.913405Z"}},"outputs":[],"execution_count":8},{"cell_type":"code","source":"word_vectors = KeyedVectors.load_word2vec_format(\"got_word2vec.txt\", binary=False)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-07T17:13:44.915480Z","iopub.execute_input":"2025-06-07T17:13:44.915792Z","iopub.status.idle":"2025-06-07T17:13:44.926671Z","shell.execute_reply.started":"2025-06-07T17:13:44.915766Z","shell.execute_reply":"2025-06-07T17:13:44.925744Z"}},"outputs":[],"execution_count":9},{"cell_type":"code","source":"def words_to_vector(text, model, vector_size=16):\n    \n    words = text.split()  # Tokenize text\n    vectors = [model[w] for w in words if w in model]  # Convert words to embeddings\n    return np.mean(vectors, axis=0) if vectors else np.zeros(vector_size)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-07T17:13:44.929303Z","iopub.execute_input":"2025-06-07T17:13:44.929620Z","iopub.status.idle":"2025-06-07T17:13:44.936105Z","shell.execute_reply.started":"2025-06-07T17:13:44.929599Z","shell.execute_reply":"2025-06-07T17:13:44.935250Z"}},"outputs":[],"execution_count":10},{"cell_type":"code","source":"x = [words_to_vector(review,word_vectors,16) for review in train_df.iloc[:,2]]\ny = train_df.iloc[:,0]\nx = np.array(x)\ny = np.array(y)\nx = x.reshape((x.shape[0], 1, x.shape[1]))","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-07T17:13:44.936980Z","iopub.execute_input":"2025-06-07T17:13:44.937298Z","iopub.status.idle":"2025-06-07T17:19:57.607361Z","shell.execute_reply.started":"2025-06-07T17:13:44.937244Z","shell.execute_reply":"2025-06-07T17:19:57.606419Z"}},"outputs":[],"execution_count":11},{"cell_type":"code","source":"import torch\nimport torch.nn as nn\nimport torchvision\nimport torchvision.transforms as transforms\n\ndevice = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\nx_tensor = torch.tensor(x, dtype=torch.float32).to(device)\ny_tensor = torch.tensor(y, dtype=torch.long).to(device)\ny_tensor = (y_tensor.view(-1, 1)).float()\ny_tensor = y_tensor - 1\nimport gc\ndel x, y\ngc.collect()\n\nclass RNN(nn.Module):\n    def __init__(self,input_size,hidden_size,num_layers,num_classes):\n        super(RNN,self).__init__()\n        self.num_layers = num_layers\n        self.hidden_size = hidden_size\n        self.rnn = nn.RNN(input_size,hidden_size,num_layers,batch_first = True,nonlinearity='tanh')\n        self.fc = nn.Sequential(\n            nn.Linear(hidden_size, 1),\n            nn.Sigmoid()\n            )\n    def forward(self, x):\n        h0 = torch.zeros(self.num_layers, x.shape[0], self.hidden_size).to(device)\n        out, _ = self.rnn(x, h0)  \n        out = out[:, -1, :]  \n        out = self.fc(out) \n        return out\n\ninput_size = 16\nhidden_size = 64\nnum_layers = 2\nnum_classes = 2\nlearning_rate = 0.01\n\nmodel = RNN(input_size,hidden_size,num_layers,num_classes).to(device)\ndel RNN,input_size,hidden_size,num_layers,\ngc.collect()\ncriterion = nn.BCEWithLogitsLoss() \noptimizer = torch.optim.Adam(model.parameters(),lr = learning_rate)\ny_tensor = y_tensor.view(-1, 1)\nfor epoch in range(100):\n    optimizer.zero_grad()  \n    outputs = model(x_tensor) \n    loss = criterion(outputs, y_tensor)  \n    loss.backward()  \n    optimizer.step() \n    del outputs\n    gc.collect()\n\n    if epoch % 10 == 0:\n        print(f'Epoch [{epoch}/100], Loss: {loss.item():.4f}')","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"del criterion,optimizer,train_df,sentences\ngc.collect()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-07T17:46:51.931634Z","iopub.execute_input":"2025-06-07T17:46:51.932204Z","iopub.status.idle":"2025-06-07T17:47:00.224152Z","shell.execute_reply.started":"2025-06-07T17:46:51.932168Z","shell.execute_reply":"2025-06-07T17:47:00.223381Z"}},"outputs":[{"execution_count":13,"output_type":"execute_result","data":{"text/plain":"0"},"metadata":{}}],"execution_count":13},{"cell_type":"code","source":"x_test = np.array([words_to_vector(review,word_vectors,16) for review in test_df.iloc[:,2]])\nx_test = x_test.reshape((x_test.shape[0], 1, x_test.shape[1]))\nx_test_tensor = torch.tensor(x_test, dtype=torch.float32).to(device)\ndel x_test,word_vectors,words_to_vector\npredictions = model(x_test_tensor)\ndel model\ngc.collect()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-07T17:47:00.225783Z","iopub.execute_input":"2025-06-07T17:47:00.226051Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"from sklearn.metrics import accuracy_score,f1_score,confusion_matrix\ny_test = np.array(test_df.iloc[:,0])\ny_test = torch.tensor(y_test, dtype=torch.long).to(device)\ny_test = (y_test.view(-1, 1)).float()\n\naccuracy = accuracy_score(y_test, predictions.cpu().numpy())\nprint(f'Accuracy: {accuracy:.4f}')\nf1 = f1_score(y_test, predictions.cpu().numpy(), average=\"binary\") \nprint(f'F1-Score: {f1:.4f}')\nconf_matrix = confusion_matrix(y_test, predictions.cpu().numpy())\nprint(\"Confusion Matrix:\")\nprint(conf_matrix)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-07T17:46:51.450439Z","iopub.status.idle":"2025-06-07T17:46:51.450766Z","shell.execute_reply.started":"2025-06-07T17:46:51.450624Z","shell.execute_reply":"2025-06-07T17:46:51.450640Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# LSTM","metadata":{}},{"cell_type":"code","source":"class LSTM(nn.Module):\n    def __init__(self, input_size, hidden_size, num_layers, num_classes):\n        super(LSTM, self).__init__()\n        self.num_layers = num_layers\n        self.hidden_size = hidden_size\n\n        # Replace RNN with LSTM\n        self.lstm = nn.LSTM(input_size, hidden_size, num_layers, batch_first=True)\n        \n        # Fully connected layer with sigmoid for binary classification\n        self.fc = nn.Sequential(\n            nn.Linear(hidden_size, num_classes),\n            nn.Sigmoid()\n        )\n\n    def forward(self, x):\n        # Initialize hidden and cell states\n        h0 = torch.zeros(self.num_layers, x.shape[0], self.hidden_size).to(device)\n        c0 = torch.zeros(self.num_layers, x.shape[0], self.hidden_size).to(device)\n\n        # Forward propagate LSTM\n        out, _ = self.lstm(x, (h0, c0))  \n        out = out[:, -1, :]  # Take last output in sequence\n        out = self.fc(out)  # Apply classification layer\n        return out\n\n# Hyperparameters\ninput_size = 16\nhidden_size = 64\nnum_layers = 2\nnum_classes = 2\nlearning_rate = 0.01\n\n# Initialize model\nmodel = LSTM(input_size, hidden_size, num_layers, num_classes).to(device)\n\n# Loss and optimizer\ncriterion = nn.BCEWithLogitsLoss()  \noptimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n\n\n# Training loop\nfor epoch in range(100):\n    optimizer.zero_grad()  \n    outputs = model(x_tensor)  # Remove `torch.no_grad()` (needed for training)\n    loss = criterion(outputs, y_tensor)  \n    loss.backward()  \n    optimizer.step() \n\n    if epoch % 10 == 0:\n        print(f'Epoch [{epoch}/100], Loss: {loss.item():.4f}')\n\n# Clean up memory\ndel x_tensor, y_tensor\ngc.collect()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-07T17:46:51.451898Z","iopub.status.idle":"2025-06-07T17:46:51.452379Z","shell.execute_reply.started":"2025-06-07T17:46:51.452159Z","shell.execute_reply":"2025-06-07T17:46:51.452180Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"predictions = model(x_test_tensor)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"accuracy = accuracy_score(y_test, predictions.cpu().numpy())\nprint(f'Accuracy: {accuracy:.4f}')\nf1 = f1_score(y_test, predictions.cpu().numpy(), average=\"binary\") \nprint(f'F1-Score: {f1:.4f}')\nconf_matrix = confusion_matrix(y_test, predictions.cpu().numpy())\nprint(\"Confusion Matrix:\")\nprint(conf_matrix)","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}